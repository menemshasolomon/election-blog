---
title: '6. On Air: The Addition of Campaign Advertising'
author: Mena Solomon
date: '2024-10-09'
slug: []
categories: []
tags: []
---

## What role does the campaign play in determining election outcomes?

Throughout the past five weeks, my blog has focused on exploring fundamentals like [the economy](https://menemshasolomon.github.io/election-blog/post/2024-09-14-2-the-importance-of-the-economy/), [polling](https://menemshasolomon.github.io/election-blog/post/2024-09-18-3-incorporating-polling/) [incumbency](https://menemshasolomon.github.io/election-blog/post/2024-09-27-4-the-incumbency-advantage/), and [demographics](https://menemshasolomon.github.io/election-blog/post/2024-10-02-5-demographics-turnout-and-vote-choice/). These discussions may generate a false understanding that elections are pre-determined, as they are predictable on a small set of fundamental variables. In reality, fundamentals only represent a partial understanding of the temperature of the American electorate. **To truly predict the outcome of presidential elections, it is also important to take into account the 6.6 billion dollar presidential campaign industry.** 

**Presidential campaigns have three main purposes — to convince donors, persuade voters, and mobilize the electorate. There are many mechanisms by which campaigns attempt to fulfill these purposes, the largest of which — the air war of mass media — will be explored below.**

```{r echo = FALSE, message=FALSE, warning=FALSE}
####----------------------------------------------------------#
#### Preamble
####----------------------------------------------------------#

# Load libraries.
## install via `install.packages("name")`
library(car)
library(caret)
library(cowplot)
library(curl)
library(CVXR)
library(foreign)
library(geofacet)
library(glmnet)
library(haven)
library(janitor)
library(kableExtra)
library(maps)
library(mlr3)
library(randomForest)
library(ranger)
library(RColorBrewer)
library(rstan)
library(scales)
library(sf)
library(shinystan)
library(tidyverse)
library(viridis)
```


```{r  echo = FALSE, message=FALSE, warning=FALSE}
####----------------------------------------------------------#
#### Read, merge, and process data.
####----------------------------------------------------------#

# Read popular vote datasets. 
d_popvote <- read_csv("data/popvote_1948_2020.csv")
d_state_popvote <- read_csv("data/state_popvote_1948_2020.csv")

# Read elector distribution dataset. 
d_ec <- read_csv("data/corrected_ec_1948_2024.csv")

# Read ads datasets. 
ad_campaigns <- read_csv("data/ad_campaigns_2000-2012.csv") ##politician themselves
ad_creative <- read_csv("data/ad_creative_2000-2012.csv") ##PACs
ads_2020 <- read_csv("data/ads_2020.csv")
facebook_ads_2020 <- read_csv("data/facebook_ads_2020.csv.zip")
facebook_ads_biden_2020 <- read_csv("data/facebook_ads_biden_2020.csv")
campaign_spending <- read_csv("data/FEC_contributions_by_state_2008_2024.csv")

# Read polling data. 
d_polls <- read_csv("data/national_polls_1968-2024.csv")
d_state_polls <- read_csv("data/state_polls_1968-2024.csv")

# Read turnout data. 
d_turnout <- read_csv("data/state_turnout_1980_2022.csv")

```

##What is the air war? How does it influence voters?

**To reach the largest number of potential voters, campaigns often turn to mass media to present their message.** The meaning of mass media has changed throughout time; however, its largest sector for the past half century has been television advertising. Indeed, according to [EMarketer](https://www.emarketer.com/press-releases/2024-political-ad-spending-will-jump-nearly-30-vs-2020/), total US political ad spending will hit $12.32 billion in 2024. 

Political advertising has two main effects — persuasion and mobilization. There are two main pieces of literature which have found proof of the influence of campaign advertising. First, Gerber and his team used a randomized control trial in Rick Perry's Texas Gubernatorial race to understand the persuasive influence of certain advertisements. By randomizing which county saw what ad, that campaign was able to determine that televised campaign ads have sizable persuasive effects, especially on undecided voters, though those effects tend to fade over time [(Gerber et al, 2011).]() Huber and Arceneaux added to this existing literature with a study of spillover media markets from battleground states, with massive ad funding, into non-battleground states, which typically have almost no ad budget. The authors found that a large influx of advertising, as is often found in battleground states, led places that saw commercials to have their votes changed as compared to the places that did not see the swing-state volume of advertisements [(Huber and Arceneaux, 2019)]().

*To understand these effects in practice, is is important to first analyze some descriptive statistics on ads and campaign spending over time.*

**The first two graphics display the volume of campaign spending in the 2000, 2004, 2008, and 2012. These graphics highlight the disparities between election ad spending in swing states vs. non-competitive states.** Interestingly, the volume of advertising as well as the states deemed most competitive have changed throughout the years. Generally speaking, however, as elections haev become more competitive over the past 25 years, campaign ad spending has increased dramatically. 

**The third emphasizes the timing of this spending, emphasizing the importance of ad spending right before election day due to the lack of ad durability (voters are often unable to retain what they learned in an advertisement for a long period). Both of these graphics also point to an important reality — campaign spending is often evenly matched.** Many scholars assert that this equal game of tug-of-war is often why campaigns have a very small effect on outcomes. Indeed, if either party were to let go of the rope, voters may be influenced; however, while the even game continues, neither will make substantial gains.

```{r  echo = FALSE, message=FALSE, warning=FALSE, fig.width=18, fig.height=9}

####--------------------------------------------------------------#
#### Descriptive statistics on ads and campaign spending over time. 
####--------------------------------------------------------------#

ad_campaigns00 <- ad_campaigns |>
  mutate(year = as.numeric(substr(air_date, 1, 4))) |>
  mutate(month = as.numeric(substr(air_date, 6, 7))) |>
  mutate(state = state.name[match(state, state.abb)]) |>
  filter(cycle == 2000) |>
  left_join(d_state_popvote |> filter(year == 2000) |> select(-year), by="state") |>
  mutate(winner=ifelse(D_pv2p > R_pv2p, "democrat", "republican")) |>
  group_by(cycle, state, air_date, party, winner) |>
  summarise(total_cost = sum(total_cost)) |>
  filter(!is.na(state)) |>
  # ggplot(aes(x=air_date, y=log(total_cost+1), color=party)) +
  ggplot(aes(x=party, y=total_cost, fill=party)) +
  geom_bar(stat="identity") +
  geom_rect(aes(fill=winner), xmin=-Inf, xmax=Inf, ymin=18.3*10^6, ymax=24*10^6) +
  facet_geo(~ state, scales="free_x") +
  scale_fill_manual(values = c("blue", "red")) +
  scale_y_continuous(labels = unit_format(unit = "M", scale = 1e-6)) +
  xlab("") + ylab("ad spend") +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())


ad_campaigns04 <- ad_campaigns |>
  mutate(year = as.numeric(substr(air_date, 1, 4))) |>
  mutate(month = as.numeric(substr(air_date, 6, 7))) |>
  mutate(state = state.name[match(state, state.abb)]) |>
  filter(cycle == 2004) |>
  left_join(d_state_popvote |> filter(year == 2004) |> select(-year), by="state") |>
  mutate(winner=ifelse(D_pv2p > R_pv2p, "democrat", "republican")) |>
  group_by(cycle, state, air_date, party, winner) |>
  summarise(total_cost = sum(total_cost)) |>
  filter(!is.na(state)) |>
  # ggplot(aes(x=air_date, y=log(total_cost+1), color=party)) +
  ggplot(aes(x=party, y=total_cost, fill=party)) +
  geom_bar(stat="identity") +
  geom_rect(aes(fill=winner), xmin=-Inf, xmax=Inf, ymin=58.3*10^6, ymax=64*10^6) +
  facet_geo(~ state, scales="free_x") +
  scale_fill_manual(values = c("blue", "red")) +
  scale_y_continuous(labels = unit_format(unit = "M", scale = 1e-6)) +
  xlab("") + ylab("ad spend") +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())


ad_campaigns08 <- ad_campaigns |>
  mutate(year = as.numeric(substr(air_date, 1, 4))) |>
  mutate(month = as.numeric(substr(air_date, 6, 7))) |>
  mutate(state = state.name[match(state, state.abb)]) |>
  filter(cycle == 2008) |>
  left_join(d_state_popvote |> filter(year == 2008) |> select(-year), by="state") |>
  mutate(winner=ifelse(D_pv2p > R_pv2p, "democrat", "republican")) |>
  group_by(cycle, state, air_date, party, winner) |>
  summarise(total_cost = sum(total_cost)) |>
  filter(!is.na(state)) |>
  # ggplot(aes(x=air_date, y=log(total_cost+1), color=party)) +
  ggplot(aes(x=party, y=total_cost, fill=party)) +
  geom_bar(stat="identity") +
  geom_rect(aes(fill=winner), xmin=-Inf, xmax=Inf, ymin=46.3*10^6, ymax=52*10^6) +
  facet_geo(~ state, scales="free_x") +
  scale_fill_manual(values = c("blue", "red")) +
  scale_y_continuous(labels = unit_format(unit = "M", scale = 1e-6)) +
  xlab("") + ylab("ad spend") +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

ad_campaigns12 <-ad_campaigns |>
  mutate(year = as.numeric(substr(air_date, 1, 4))) |>
  mutate(month = as.numeric(substr(air_date, 6, 7))) |>
  mutate(state = state.name[match(state, state.abb)]) |>
  filter(cycle == 2012) |>
  left_join(d_state_popvote |> filter(year == 2012) |> select(-year), by="state") |>
  mutate(winner=ifelse(D_pv2p > R_pv2p, "democrat", "republican")) |>
  group_by(cycle, state, air_date, party, winner) |>
  summarise(total_cost = sum(total_cost)) |>
  filter(!is.na(state)) |>
  # ggplot(aes(x=air_date, y=log(total_cost+1), color=party)) +
  ggplot(aes(x=party, y=total_cost, fill=party)) +
  geom_bar(stat="identity") +
  geom_rect(aes(fill=winner), xmin=-Inf, xmax=Inf, ymin=116.3*10^6, ymax=122*10^6) +
  facet_geo(~ state, scales="free_x") +
  scale_fill_manual(values = c("blue", "red")) +
  scale_y_continuous(labels = unit_format(unit = "M", scale = 1e-6)) +
  xlab("") + ylab("ad spend") +
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())


library(gridExtra)

grid.arrange(ad_campaigns00, ad_campaigns04, nrow = 1)
grid.arrange(ad_campaigns08, ad_campaigns12,nrow = 1)

## When to Buy Ads? 
ad_campaigns |>
  mutate(year = as.numeric(substr(air_date, 1, 4))) |>
  mutate(month = as.numeric(substr(air_date, 6, 7))) |>
  filter(year %in% c(2000, 2004, 2008, 2012), month > 7) |>
  group_by(cycle, air_date, party) |>
  summarise(total_cost = sum(total_cost)) |>
  ggplot(aes(x=air_date, y=total_cost, color=party)) +
  # scale_x_date(date_labels = "%b, %Y") +
  scale_y_continuous(labels = dollar_format()) +
  scale_color_manual(values = c("blue","red"), name = "") +
  geom_line() + geom_point(size=0.5) +
  facet_wrap(cycle ~ ., scales="free") +
  xlab("") + ylab("ad spend") +
  theme_bw() +
  theme(axis.title = element_text(size=20),
        axis.text = element_text(size=11),
        strip.text.x = element_text(size = 20))

```

Despite this hypothesis, advertising is still an important way that campaigns convey their message to the general public. Furthermore, despite similarities in the volume of these advertisements, the content differences between parties are immense. The graphics below highlight differentials in terms of the policy and tone of both parties' advertisements.

The first two explore campaign aids by tone and purpose. For the most part, the proportions in each graph are similar, showing that trends in political advertising content are somewhat consistent. The one exception to this trend would be the purpose of advertisements in 2016. The main reason for this difference is that 2016 data was imputed, as it is not yet available in the correct format.

```{r   echo = FALSE, message=FALSE, warning=FALSE, fig.width = 16, fig.height = 6}


# Tone and Political Ads. 
tone <- ad_campaigns |>
  left_join(ad_creative) |>
  group_by(cycle, party) |> mutate(tot_n=n()) |> ungroup() |>
  group_by(cycle, party, ad_tone) |> summarise(pct=n()*100/first(tot_n)) |>
  filter(!is.na(ad_tone)) |>
  ggplot(aes(x = cycle, y = pct, fill = ad_tone, group = party)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = seq(2000, 2012, 4)) +
  ggtitle("Campaign Ads Aired By Tone") +
  scale_fill_manual(values = c("darkseagreen1","forestgreen","lightgreen","darkgreen","white"), name = "tone") +
  xlab("") + ylab("%") +
  facet_wrap(~ party) + theme_minimal() +
  theme(axis.title = element_text(size=20),
        axis.text = element_text(size=15),
        strip.text.x = element_text(size = 20))

## The Purpose of Political Ads (2016 personal outlier, comes from dif. data source)
purpose <- ad_campaigns |>
  left_join(ad_creative) |>
  group_by(cycle, party) |> mutate(tot_n=n()) |> ungroup() |>
  group_by(cycle, party, ad_purpose) |> summarise(pct=n()*100/first(tot_n)) |>
  filter(!is.na(ad_purpose)) |>
  bind_rows( ##2016 raw data not public yet! This was entered manually
    data.frame(cycle = 2016, ad_purpose = "personal", party = "democrat", pct = 67),
    data.frame(cycle = 2016, ad_purpose = "policy", party = "democrat", pct = 12),
    data.frame(cycle = 2016, ad_purpose = "both", party = "democrat", pct = 21),
    data.frame(cycle = 2016, ad_purpose = "personal", party = "republican", pct = 11),
    data.frame(cycle = 2016, ad_purpose = "policy", party = "republican", pct = 71),
    data.frame(cycle = 2016, ad_purpose = "both", party = "republican", pct = 18)
  ) |>
  ggplot(aes(x = cycle, y = pct, fill = ad_purpose, group = party)) +
  geom_bar(stat = "identity") +
  scale_x_continuous(breaks = seq(2000, 2016, 4)) +
  ggtitle("Campaign Ads Aired By Purpose") +
  scale_fill_manual(values = c("deeppink1","deeppink4","mistyrose","lightpink1","white"), name = "purpose") +
  xlab("") + ylab("%") +
  facet_wrap(~ party) + theme_minimal() +
  theme(axis.title = element_text(size=20),
        axis.text = element_text(size=15),
        strip.text.x = element_text(size = 20))

grid.arrange(tone, purpose, nrow = 1)

```

Furthermore, the figure below emphasizes bipartisan shifts in tone depending on the election cycle. While the 2000 and 2008 campaigns focused on promotional content, 2004 and 2012 carried a lot of attack ads. One potential reason for this could be the role of incumbency, wherein Bush and Obama did not have to focus as heavily on promoting their views while Cheney and Romney were forced to attack the incumbent to make headway in the election.

```{r}
## Tone in Political Ads
ad_campaigns |>
  left_join(ad_creative) |>
  filter(ad_tone %in% c("attack", "promote")) |>
  mutate(year = as.numeric(substr(air_date, 1, 4))) |>
  mutate(month = as.numeric(substr(air_date, 6, 7))) |>
  filter(year %in% c(2000, 2004, 2008, 2012), month > 7) |>
  group_by(cycle, air_date, ad_tone) |>
  summarise(total_cost = sum(n_stations)) |>
  group_by(cycle, air_date) |>
  mutate(total_cost = total_cost/sum(total_cost)) |>
  ungroup() |>
  ggplot(aes(x=air_date, y=total_cost, fill=ad_tone, color=ad_tone)) +
  # scale_x_date(date_labels = "%b") +
  scale_fill_manual(values = c("lightpink1","darkseagreen1"), name = "ad tone") +
  scale_color_manual(values = c("lightpink1","darkseagreen1"), name = "ad tone") +
  geom_bar(stat = "identity") +
  facet_wrap(cycle ~ ., scales="free") +
  xlab("") + ylab("% of ads bought on day") +
  theme_bw() +
  theme(axis.title = element_text(size=20),
        axis.text = element_text(size=10),
        strip.text.x = element_text(size = 20))
```


The final figure displays campaign ads aired by issue and party in both 2000 and 2012. As discussed above, there are consistencies across party and year with regard to the tone and purpose of advertising; however, the policy discussed changes substantially depending on the election cycle. As discussed above, advertisements are done with the goal of persuading voters to select a certain candidate. Since fundamental factors cannot be controlled, ads are used to convince voters that a candidate will better serve the electorate on each of these contested factors. As seen by the graphs, in 2000 Democrats were focused on poverty and other social issues while Repulicans were focused on drugs and China. In 2012, however, Republicans were still focused on drugs and crime while democrats were now consumed with the war on Afghanistan. 

```{r, fig.width = 16, fig.height = 6}

## Campaign Ads Aired By Issue and Party: 2000
party_issues2000 <- ad_campaigns |>
  filter(cycle == 2000) |>
  left_join(ad_creative) |>
  filter(ad_issue != "None") |>
  ## this `group_by` is to get our denominator
  group_by(ad_issue) |> mutate(tot_n=n()) |> ungroup() |>
  ## this one is get numerator and calculate % by party
  group_by(ad_issue, party) |> summarise(p_n=n()*100/first(tot_n)) |> ungroup() |>
  ## finally, this one so we can sort the issue names
  ## by D% of issue ad-share instead of alphabetically
  group_by(ad_issue) |> mutate(Dp_n = ifelse(first(party) == "democrat", first(p_n), 0))

party_issues2000_graph <- ggplot(party_issues2000, aes(x = reorder(ad_issue, Dp_n), y = p_n, fill = party)) + 
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("blue", "red")) +
  ylab("% of ads on topic from each party") + xlab("issue") + 
  # ggtitle("Campaign Ads Aired by Topic in 2000") +
  coord_flip() + 
  theme_bw()

## Campaign Ads Aired By Issue and Party: 2012
party_issues2012 <- party_issues2012 <- ad_campaigns |>
  filter(cycle == 2012) |>
  left_join(ad_creative) |>
  filter(ad_issue != "None") |>
  group_by(cycle, ad_issue) |> mutate(tot_n=n()) |> ungroup() |>
  group_by(cycle, ad_issue, party) |> summarise(p_n=n()*100/first(tot_n)) |> ungroup() |>
  group_by(cycle, ad_issue) |> mutate(Dp_n = ifelse(first(party) == "democrat", first(p_n), 0))

party_issues2012_graph <-  ggplot(party_issues2012, aes(x = reorder(ad_issue, Dp_n), y = p_n, fill = party)) + 
  geom_bar(stat = "identity") +
  scale_fill_manual(values = c("blue", "red")) +
  ylab("% of ads on topic from each party") + xlab("issue") +
  # ggtitle("Campaign Ads Aired by Topic in 2012") +
  coord_flip() + 
  theme_bw()
party_issues2000_grob <- ggplotGrob(party_issues2000_graph)
party_issues2012_grob <- ggplotGrob(party_issues2012_graph)

grid.arrange(party_issues2000_grob, party_issues2012_grob, nrow = 1)

```

## How can campaign spending be used to predict election outcomes?

```{r   echo = FALSE, message=FALSE, warning=FALSE}
# Estimate state-level regression of vote share on campaign spending. 
d_campaign_spending <- d_state_popvote |> 
  mutate(state_abb = state.abb[match(d_state_popvote$state, state.name)]) |> 
  left_join(campaign_spending |> filter(party == "Democrat"), by = c("year" = "election_year", "state_abb" = "contribution_state")) |> 
  filter(year >= 2008)

lm(D_pv ~ contribution_receipt_amount, 
   data = d_campaign_spending) |> summary()

# when pv2p is the outcome variable, campaign spending is typically less predictive because both campaigns are usually neck and neck in spending (and) so as to diminish the effect of spending on support

lm(D_pv2p ~ contribution_receipt_amount, 
   data = d_campaign_spending) |> summary()

lm(D_pv ~ contribution_receipt_amount + factor(state), 
   data = d_campaign_spending) |> summary()

lm(D_pv2p ~ contribution_receipt_amount + factor(state), 
   data = d_campaign_spending) |> summary()


# Log transformation of spending. - makes the variable far less right skewed 
lm(D_pv ~ log(contribution_receipt_amount), 
   data = d_campaign_spending) |> summary()

lm(D_pv2p ~ log(contribution_receipt_amount), 
   data = d_campaign_spending) |> summary()

lm(D_pv ~ log(contribution_receipt_amount) + factor(state), 
   data = d_campaign_spending) |> summary()

lm(D_pv2p ~ log(contribution_receipt_amount) + factor(state), 
   data = d_campaign_spending) |> summary() # Why might this be? 

```

Take a prior belief about the prability of a certain outcome, combine it with data, then update final belief
- bayesian is flexible to many different probability distributions (OLD is biased towards only accepting normal distributions)
- random variable with probability distribution
- uncertainty takes the form of credible intervals, 95% that real value is within the constructed interval
- conditional probability of one even occurring conditional on other event is the probability of both events occurring / probability of the conditional occurring
- see slides for more information! 

frequentist statistics (what we have been using this far) assume that paramneters are fixed and unknown, they they rely on the central limit theory that using repeated sampling the estimators converge and are unbiased
- uncertainty takes the form of confidence internals i.e. 95% of intervals trap the true parameter value

linear regression can have a bayesian analogue IF we treat the model parameters as random variables with probability distributions.
```{r   echo = FALSE, message=FALSE, warning=FALSE}
####--------------------------------------------------------------#
#### Bayesianism.
####--------------------------------------------------------------#

# Process state-level polling data.
d_pollav_state <- d_state_polls |>
  group_by(year, state, party) |>
  mutate(mean_pollav = mean(poll_support, na.rm = TRUE)) |>
  top_n(1, poll_date) |>
  rename(latest_pollav = poll_support) |>
  select(-c(weeks_left, days_left, poll_date, candidate, before_convention)) |>
  pivot_wider(names_from = party, values_from = c(latest_pollav, mean_pollav))

# Merge data.
d <- d_pollav_state |>
  left_join(d_state_popvote, by = c("year", "state")) |>
  left_join(d_popvote |> filter(party == "democrat"), by = "year") |>
  left_join(d_turnout, by = c("year", "state")) |>
  filter(year >= 1980) |>
  ungroup()

# Sequester states for which we have polling data for 2024.
states.2024 <- unique(d$state[d$year == 2024])
states.2024 <- states.2024[-which(states.2024 == "Nebraska Cd 2")]
d <- d |>
  filter(state %in% states.2024)

# Separate into training and testing for simple poll prediction model. 
d.train <- d |> filter(year < 2024) |> select(year, state, D_pv2p, latest_pollav_DEM, mean_pollav_DEM, 
                                              D_pv2p_lag1, D_pv2p_lag2) |> drop_na()
d.test <- d |> filter(year == 2024) |> select(year, state, D_pv2p, latest_pollav_DEM, mean_pollav_DEM, 
                                              D_pv2p_lag1, D_pv2p_lag2)

# Add back in lagged vote share for 2024. 
t <- d |> 
  filter(year >= 2016) |> 
  arrange(year) |> 
  group_by(state) |> 
  mutate(
    D_pv2p_lag1 = lag(D_pv2p, 1),
    R_pv2p_lag1 = lag(R_pv2p, 1), 
    D_pv2p_lag2 = lag(D_pv2p, 2),
    R_pv2p_lag2 = lag(R_pv2p, 2)) |> 
  filter(year == 2024) |> 
  select(state, year, D_pv2p, R_pv2p, D_pv2p_lag1, R_pv2p_lag1, D_pv2p_lag2, R_pv2p_lag2) 

# Subset testing data to only relevant variables for our simple model. 
d.test <- d.test |> 
  select(-c(D_pv2p, D_pv2p_lag1, D_pv2p_lag2)) |> 
  left_join(t, by = c("state", "year"))

# Standard frequentist linear regression. (what we ahve been doing thus far in the class)
reg.ols <- lm(D_pv2p ~ latest_pollav_DEM + mean_pollav_DEM + D_pv2p_lag1 + D_pv2p_lag2, 
              data = d.train)
summary(reg.ols)
pred.ols.dem <- predict(reg.ols, newdata = d.test)

# Create dataset to summarize winners and EC vote distributions. 
win_pred <- data.frame(state = d.test$state,
                       year = rep(2024, length(d.test$state)),
                       simp_pred_dem = pred.ols.dem,
                       simp_pred_rep = 100 - pred.ols.dem) |> 
            mutate(winner = ifelse(simp_pred_dem > simp_pred_rep, "Democrat", "Republican")) |>
            left_join(d_ec, by = c("state", "year"))

win_pred

win_pred |> 
  filter(winner == "Democrat") |> 
  select(state)

win_pred |> 
  filter(winner == "Republican") |> 
  select(state)

win_pred |> 
  group_by(winner) |> 
  summarize(n = n(), ec = sum(electors))

# Bayesian linear regression using STAN. (new model who requires a list of data not a data frame)
stan.data <- list(N = nrow(d.train), 
                  D_pv2p = d.train$D_pv2p, 
                  latest_pollav_DEM = d.train$latest_pollav_DEM, 
                  mean_pollav_DEM = d.train$mean_pollav_DEM, 
                  D_pv2p_lag1 = d.train$D_pv2p_lag1, 
                  D_pv2p_lag2 = d.train$D_pv2p_lag2)

# 3 parts of bayesian model: data, pramateres, model --> in this case, frequentist alighs with bayesian (and bayuesian is not necessarily helpful in this case)
stan.code <- "
data {
  int<lower=0> N;
  vector[N] D_pv2p;
  vector[N] latest_pollav_DEM;
  vector[N] mean_pollav_DEM;
  vector[N] D_pv2p_lag1;
  vector[N] D_pv2p_lag2;
} "

# four coefficients correspond to four variable chosen above
stan.code <- paste(stan.code, "
parameters {
  real alpha;
  real beta1;
  real beta2;
  real beta3;
  real beta4;
  real<lower=0> sigma;
} ")

stan.code <- paste(stan.code, "
model {
  D_pv2p ~ normal(alpha + beta1*latest_pollav_DEM + beta2*mean_pollav_DEM + beta3*D_pv2p_lag1 + beta4*D_pv2p_lag2, sigma);
} ")

stan.model <- stan_model(model_code = stan.code)

stan.fit <- sampling(stan.model, data = stan.data, chains = 4, iter = 4000, warmup = 1000)

# Compare coefficients from frequentist and Bayesian linear regressions. 
coef(reg.ols)
confint(reg.ols)
print(stan.fit, pars = c("alpha", "beta1", "beta2", "beta3", "beta4", "sigma"))
```

